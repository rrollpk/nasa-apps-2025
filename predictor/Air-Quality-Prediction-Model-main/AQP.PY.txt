# Import necessary libraries
import requests
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Step 1: Fetch Real-Time Air Quality Data
def fetch_air_quality_data(api_key, city, state, country):
    """
    Fetches real-time air quality data using the AirVisual API.
    """
    url = f"http://api.airvisual.com/v2/city?city={city}&state={state}&country={country}&key={api_key}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        pollutants = data['data']['current']['pollution']
        return pollutants
    else:
        print("Failed to fetch data")
        return None

# Step 2: Load and Preprocess Historical Data
def load_and_preprocess_data(file_path):
    """
    Loads historical air quality data and preprocesses it for training.
    """
    # Load dataset
    data = pd.read_csv(file_path)
    
    # Features and target
    X = data[['PM2.5', 'PM10', 'NO2', 'CO', 'O3', 'SO2']]  # Features
    y = data['AQI']  # Target
    
    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Standardize features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    return X_train, X_test, y_train, y_test, scaler

# Step 3: Train a Machine Learning Model
def train_model(X_train, y_train):
    """
    Trains a Random Forest Regressor model.
    """
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    return model

# Step 4: Evaluate the Model
def evaluate_model(model, X_test, y_test):
    """
    Evaluates the model using Mean Squared Error (MSE).
    """
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    print(f"Mean Squared Error: {mse}")

# Step 5: Make Real-Time Predictions
def predict_real_time_aqi(model, scaler, pollutants):
    """
    Predicts AQI using real-time pollutant data.
    """
    # Prepare input data
    real_time_data = [pollutants['pm25'], pollutants['pm10'], pollutants['no2'], 
                      pollutants['co'], pollutants['o3'], pollutants['so2']]
    real_time_data = scaler.transform([real_time_data])
    
    # Predict AQI
    predicted_aqi = model.predict(real_time_data)
    return predicted_aqi[0]

# Main Function
def main():
    # API key and location details
    api_key = 'your_api_key_here'  # Replace with your AirVisual API key
    city = 'Los Angeles'
    state = 'California'
    country = 'USA'
    
    # Step 1: Fetch real-time air quality data
    pollutants = fetch_air_quality_data(api_key, city, state, country)
    if pollutants:
        print("Fetched Real-Time Pollutants:", pollutants)
        
        # Step 2: Load and preprocess historical data
        file_path = 'air_quality_data.csv'  # Replace with your dataset path
        X_train, X_test, y_train, y_test, scaler = load_and_preprocess_data(file_path)
        
        # Step 3: Train the model
        model = train_model(X_train, y_train)
        
        # Step 4: Evaluate the model
        evaluate_model(model, X_test, y_test)
        
        # Step 5: Make real-time predictions
        predicted_aqi = predict_real_time_aqi(model, scaler, pollutants)
        print(f"Predicted AQI: {predicted_aqi}")
    else:
        print("Failed to fetch real-time data. Please check your API key or network connection.")

# Run the program
if __name__ == "__main__":
    main()